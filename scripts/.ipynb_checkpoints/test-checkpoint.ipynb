{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba147d37-0c10-423c-8ea0-a28322184327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import slack\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "env_path = Path('.')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai.api_key = token=os.environ['CHAT_TOKEN']\n",
    "\n",
    "def get_html(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html_content = response.read().decode(\"utf-8\")\n",
    "    return html_content\n",
    "def get_pdf(url):\n",
    "    arxiv_id = url[22:]\n",
    "    url = \"https://arxiv.org/pdf/\" + arxiv_id + \".pdf\"\n",
    "    response = requests.get(url)\n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Step 2: Converting the PDF to a more readable format\n",
    "        with BytesIO(response.content) as open_pdf_file:\n",
    "            pdf = PyPDF2.PdfReader(open_pdf_file)\n",
    "            return pdf\n",
    "    else:\n",
    "        return(\"Pattern not found [Failed match flag]\")\n",
    "def get_pdf_text(url):\n",
    "    arxiv_id = url[22:]\n",
    "    url = \"https://arxiv.org/pdf/\" + arxiv_id + \".pdf\"\n",
    "    response = requests.get(url)\n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Step 2: Converting the PDF to a more readable format\n",
    "        with BytesIO(response.content) as open_pdf_file:\n",
    "            read_pdf = PyPDF2.PdfReader(open_pdf_file)\n",
    "            num_pages = len(read_pdf.pages)\n",
    "            # Step 3: Extracting the text\n",
    "            text_content = \"\"\n",
    "            for i in range(num_pages):\n",
    "                page = read_pdf.pages[i]\n",
    "                text_content += page.extract_text()\n",
    "        return(text_content)\n",
    "    else:\n",
    "        return(\"Pattern not found [Failed match flag]\")\n",
    "def fetch_abstract_from_html(url):\n",
    "    pattern = r'<meta property=\"og:description\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Pdf not found [Failed match flag]\")\n",
    "def fetch_abstract(text):\n",
    "    #print(text)\n",
    "    pattern = r'Abstract(.*?).\\n1'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_conclusion(text):\n",
    "    #print(text)\n",
    "    pattern = r'Conclusion(.*?)Acknowledgments'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Conclusion not found [Failed match flag]\")\n",
    "def fetch_introduction(text):\n",
    "    #eturn(text)\n",
    "    pattern = r'Introduction(.*?).\\n2'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Introduction not found [Failed match flag]\")\n",
    "def remove_newlinechar(user_message):\n",
    "    pattern = r'\\n'\n",
    "    match = re.search(pattern, user_message, re.DOTALL)\n",
    "    if match:\n",
    "        pings = match.group(0)\n",
    "        user_message = user_message.replace(str(pings), \" \")\n",
    "    return(user_message)\n",
    "def fetch_authors_from_html(url):\n",
    "    pattern = r'<meta name=\"citation_author\" content=\"(.*?)\" />'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.findall(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        return(match)\n",
    "    else:\n",
    "        return(\"Authors not found [Failed match flag]\")\n",
    "def fetch_title_from_html(url):\n",
    "    pattern = r'<meta name=\"twitter:title\" content=\"(.*?)\"/>'\n",
    "    html_content = str(get_html(url))\n",
    "    match = re.search(pattern, html_content, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_content = match.group(1)\n",
    "        return(extracted_content)\n",
    "    else:\n",
    "        return(\"Title not found [Failed match flag]\")\n",
    "    \n",
    "\n",
    "################################################\n",
    "###########  FUNCTIONS FOR MATEO  ##############\n",
    "################################################\n",
    "def get_title(url):\n",
    "    return fetch_title_from_html(url)\n",
    "def get_authors(url):\n",
    "    return fetch_authors_from_html(url)\n",
    "def get_abstract(url):\n",
    "    return fetch_abstract_from_html(url)\n",
    "def get_introduction(url):\n",
    "    return remove_newlinechar(fetch_introduction(get_pdf_text(url)))\n",
    "def get_conclusion(url):\n",
    "    return fetch_conclusion(remove_newlinechar(get_pdf_text(url)))\n",
    "def fetch_everything(url):\n",
    "    pdf = get_pdf_text(url)\n",
    "    content = {}\n",
    "    content[\"title\"] = get_title(url)\n",
    "    content[\"authors\"] = get_authors(url)\n",
    "    content[\"abstract\"] =  get_abstract(url)\n",
    "    content[\"introduction\"] = fetch_introduction(pdf)\n",
    "    content[\"conclusion\"] =  fetch_conclusion(pdf)\n",
    "    content[\"firstpage\"] = \"[Failed match flag]\"\n",
    "    return content\n",
    "def fetch_everything_from_pdf(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        pdf = PyPDF2.PdfReader(f)\n",
    "        num_pages = len(pdf.pages)\n",
    "        firstpage = pdf.pages[0].extract_text()\n",
    "        text = \"\"\n",
    "        for i in range(num_pages):\n",
    "            page = pdf.pages[i]\n",
    "            text += page.extract_text()\n",
    "    content = {}\n",
    "    content[\"title\"] = \"\"\n",
    "    content[\"authors\"] = [\"\"]\n",
    "    content[\"abstract\"] =  \"\"\n",
    "    content[\"introduction\"] = fetch_introduction(text)\n",
    "    content[\"conclusion\"] =  fetch_conclusion(text)\n",
    "    content[\"firstpage\"] = firstpage\n",
    "    return content\n",
    "def append_title(meta_prompt, title):\n",
    "    if (\"[Failed match flag]\" not in title):\n",
    "        meta_prompt += \"Summarize the following paper titled \\\"\" + title + \"\\\" \"\n",
    "    else:\n",
    "        meta_prompt += \"Summarize the following paper \"\n",
    "    return meta_prompt\n",
    "def append_authors(meta_prompt, authors):\n",
    "    if (\"[Failed match flag]\" in authors):\n",
    "        return meta_prompt\n",
    "    if (len(authors) == 1):\n",
    "        return meta_prompt + \"writen by \" + authors[0] + \" \"\n",
    "    meta_prompt += \"written by \"\n",
    "    for i in range(len(authors)-1):\n",
    "        meta_prompt += authors[i] + \", \"\n",
    "    meta_prompt += authors[-1] + \" \"\n",
    "    return meta_prompt\n",
    "# Levels = [\"child\", \"teenager\", \"undergraduate\", \"graduate\", \"phd\"]\n",
    "def append_level(meta_prompt, level):\n",
    "    if level == \"child\":\n",
    "        return meta_prompt + \"such that a child could understand it:\\n\"\n",
    "    if level == \"teenager\":\n",
    "        return meta_prompt + \"such that a teenager could understand it:\\n\"\n",
    "    if level == \"undergraduate\":\n",
    "        return meta_prompt + \"at the level of an undergraduate:\\n\"\n",
    "    if level == \"graduate\":\n",
    "        return meta_prompt + \"to a graduate or masters program audience:\\n\"\n",
    "    if level == \"phd\":\n",
    "        return meta_prompt + \"to a phd, do not leave out technicalities:\\n\"\n",
    "def append_abstract(meta_prompt, abstract):\n",
    "    if (\"[Failed match flag]\" in abstract):\n",
    "        return meta_prompt\n",
    "    abstract = remove_newlinechar(abstract)\n",
    "    meta_prompt += \"Abstract: \" + abstract + \"\\n\"\n",
    "    return meta_prompt\n",
    "def append_introduction(meta_prompt, introduction):\n",
    "    if (\"[Failed match flag]\" in introduction):\n",
    "        return meta_prompt\n",
    "    introduction = remove_newlinechar(introduction)\n",
    "    meta_prompt += \"Introduction: \" + introduction + \"\\n\"\n",
    "    return meta_prompt\n",
    "def append_conclusion(meta_prompt, conclusion):\n",
    "    if (\"[Failed match flag]\" in conclusion):\n",
    "        return meta_prompt\n",
    "    conclusion = remove_newlinechar(conclusion)\n",
    "    meta_prompt += \"Conclusion: \" + conclusion + \"\\n\"\n",
    "    return meta_prompt\n",
    "def append_firstpage(meta_prompt, firstpage):\n",
    "    if (\"[Failed match flag]\" in firstpage):\n",
    "        return meta_prompt\n",
    "    firstpage = remove_newlinechar(firstpage)\n",
    "    meta_prompt += \"First page of paper: \" + firstpage + \"\\n\"\n",
    "    return meta_prompt\n",
    "def format_meta_prompt(content, level):\n",
    "    meta_prompt = \"\"\n",
    "    meta_prompt = append_title(meta_prompt, content[\"title\"])\n",
    "    meta_prompt = append_authors(meta_prompt, content[\"authors\"])\n",
    "    meta_prompt = append_level(meta_prompt, level)\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_abstract(meta_prompt, content[\"abstract\"])\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_introduction(meta_prompt, content[\"introduction\"])\n",
    "    meta_prompt += \"\\n\"\n",
    "    meta_prompt = append_conclusion(meta_prompt, content[\"conclusion\"])\n",
    "    meta_prompt = append_firstpage(meta_prompt, content[\"firstpage\"])\n",
    "    return meta_prompt\n",
    "\n",
    "\n",
    "\n",
    "##### Function for Mateoooooo #################\n",
    "# for level, select from \"child\", \"teenager\", \"undegraduate\", \"graduate\", \"phd\" \n",
    "def poindexter(url = \"\", pdfpath = \"\", level = \"child\"):\n",
    "    if url != \"\":\n",
    "        content = fetch_everything(url)\n",
    "    elif filepath != \"\":\n",
    "        content = fetch_everything_from_pdf(pdfpath)\n",
    "        print(\"pdf detected\")\n",
    "    \n",
    "    meta_prompt = format_meta_prompt(content, level)\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo-16k\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": meta_prompt},\n",
    "    ],\n",
    "    max_tokens = 500,\n",
    "    temperature = 0.8,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\"\"\"\n",
    "Levels = [\"child\", \"teenager\", \"undergraduate\", \"graduate\", \"phd\"]\n",
    "To call poindexter, needs either url or pdfpath\n",
    "poindexter(\n",
    "    url = string to url (optional), \n",
    "    pdfpath = path to pdf (optional),\n",
    "    level = something from \"Levels\"\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f0d734-9621-47af-ac82-8bcb9d8f0fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper is about a new method called \"Contrast with Reconstruct\" (RECON) that combines two different ways of teaching computers to understand 3D images. The first way is called \"contrastive modeling\" which focuses on comparing different images to learn patterns. The second way is called \"generative modeling\" which focuses on creating new images based on existing ones. The authors found that each method has its own strengths and weaknesses, so they created a new method that combines the best of both. They trained a computer model called RECON to learn from both contrastive and generative models. The RECON model achieved better results in understanding 3D images compared to other methods.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Test stuff ##\n",
    "test_url = \"https://arxiv.org/abs/2205.03451\"\n",
    "filepath = \"/home/myshell/work/Poindexter/scripts/pdf/\"\n",
    "pdfname = \"2302.02318.pdf\"\n",
    "filepath += pdfname\n",
    "test = \"https://arxiv.org/abs/2205.03451\"\n",
    "\n",
    "poindexter(\n",
    "    url = \"\",\n",
    "    pdfpath = filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c24c1c-7add-4eb2-a60b-d94031cdd1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
